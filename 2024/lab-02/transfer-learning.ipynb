{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad9bb777",
   "metadata": {},
   "source": [
    "# Transfer Learning: From Theory to Practice\n",
    "\n",
    "Welcome to this Jupyter notebook on Transfer Learning! This tutorial will take you on a fun, easy-to-understand journey through one of the most important topics in modern machine learning: transfer learning.\n",
    "\n",
    "## What is Transfer Learning?\n",
    "\n",
    "Transfer Learning is a machine learning strategy where a model trained on one problem is used in some way on a second related problem. It's like teaching your computer some skills in one area and then applying these skills to a different but related task.\n",
    "\n",
    "For example, imagine you learned to play the guitar. You've never played the violin, but because of your guitar-playing skills, it's easier to learn the violin compared to someone who's never played a musical instrument before. Transfer learning works in a similar way.\n",
    "\n",
    "## Why is it Important?\n",
    "\n",
    "In the world of machine learning, transfer learning is important for a couple of reasons:\n",
    "\n",
    "1. **Less Data:** If you have a small amount of data for your problem, but your problem is similar to one for which a model was already trained, then transfer learning can help you by leveraging the already learned features.\n",
    "\n",
    "2. **Less Time and Resources:** Training a deep learning model from scratch requires a lot of time, resources, and data. If a pre-trained model is used, it can save a lot of time and computational resources.\n",
    "\n",
    "## Transfer Learning Variations\n",
    "\n",
    "There are primarily two ways we use a pre-trained model in Transfer Learning:\n",
    "\n",
    "1. **Fine-tuning:** Here we adjust (or “fine-tune”) the weights of the pre-trained model to accomplish a new task.\n",
    "\n",
    "2. **Feature Extraction:** Here, we treat the pre-trained model as an arbitrary feature extractor, allowing it to extract useful features from new data. We then use these features to train new layers of the network for a new task.\n",
    "\n",
    "Today, we are going to follow these steps on a pre-trained ResNet model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049fc320",
   "metadata": {},
   "source": [
    "## Import necessary libraries and modules\n",
    "torch is the State of the Art library for building deep learning models. OpenAI uses torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a40ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "from torch import nn, optim, Tensor\n",
    "from plotly import express as px\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a53c463",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define device - use GPU if available, else use CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "display(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e76c6f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Here we'll define some reusable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc16aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hymenoptera_data():\n",
    "    # URL of the .zip file\n",
    "    url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "    hymenoptera_zip = current_working_directory / \"hymenoptera_data.zip\"\n",
    "\n",
    "    # Send an HTTP request to the URL of the .zip file and save it to the current directory\n",
    "    response = requests.get(url)\n",
    "    hymenoptera_zip.write_bytes(response.content)\n",
    "\n",
    "    # Extract the .zip file into the current directory\n",
    "    with zipfile.ZipFile(hymenoptera_zip, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(current_working_directory)\n",
    "\n",
    "    # Remove the .zip file as it's no longer needed\n",
    "    hymenoptera_zip.unlink()\n",
    "    data_directory = current_working_directory / \"hymenoptera_data\"\n",
    "    return data_directory\n",
    "\n",
    "\n",
    "def plot_image(input_image: Tensor, title: str = None):\n",
    "    \"\"\"\n",
    "    Function to display an image from tensor\n",
    "    \"\"\"\n",
    "    # Convert image to numpy\n",
    "    input_image = input_image.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    input_image = std * input_image + mean\n",
    "    input_image = np.clip(input_image, 0, 1)\n",
    "    fig = px.imshow(input_image)\n",
    "    if title is not None:\n",
    "        fig.update_layout(title=title)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, max_epochs=50, max_time=120):\n",
    "    \"\"\"\n",
    "    Function to train a model\n",
    "\n",
    "    Arguments:\n",
    "    model : The model to be trained\n",
    "    criterion : The loss function\n",
    "    optimizer : The optimization function\n",
    "    scheduler : Learning rate scheduler for adjusting the learning rate during training\n",
    "    num_epochs : Number of epochs for training the model (default is 25)\n",
    "\n",
    "    Returns:\n",
    "    model : The trained model with the best validation accuracy\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    elapsed_time = 0\n",
    "    epoch = 1\n",
    "\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    while epoch <= max_epochs and elapsed_time <= max_time:\n",
    "        print(f\"Epoch {epoch} / {max_epochs}, {elapsed_time}s / {max_time}s\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in data_loaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(predictions == labels.data)\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "\n",
    "            # Calculate the epoch's average loss and accuracy\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # Keep a copy of the best performing model\n",
    "            if phase == \"val\" and epoch_acc > best_accuracy:\n",
    "                best_accuracy = epoch_acc\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "        epoch += 1\n",
    "        elapsed_time = round(time.time() - start_time, ndigits=1)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_accuracy:4f}\")\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model\n",
    "\n",
    "\n",
    "def visualize_model_predictions(model, batches=1):\n",
    "    \"\"\"\n",
    "    Visualize model predictions for a specific number of images.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained model.\n",
    "        number_of_images (int, optional): Number of images to display. Default is 6.\n",
    "    \"\"\"\n",
    "    was_training = model.training\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(data_loaders[\"val\"]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Make a grid from the images\n",
    "            image_grid = torchvision.utils.make_grid(inputs.cpu().data)\n",
    "\n",
    "            # Get the class names for each prediction\n",
    "            predicted_class_names = [class_names[x] for x in predictions]\n",
    "\n",
    "            # Show the images with predicted class names as titles\n",
    "            plot_image(image_grid, title=\", \".join(predicted_class_names))\n",
    "\n",
    "            batches -= 1\n",
    "            if batches <= 0:\n",
    "                break  # We only need one batch\n",
    "\n",
    "    model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a7f01",
   "metadata": {
    "id": "e8256f3d"
   },
   "source": [
    "## Download and prepare the data\n",
    "\n",
    "We're going to use just pictures of bees and ants from a popular AI dataset with hundreds of thousands of photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152b9c9",
   "metadata": {
    "id": "fda7233b"
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "data_transformations = {\n",
    "    # Data augmentation and normalization for training\n",
    "    \"train\": torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.RandomResizedCrop(224),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    # Just normalization for validation (no flipping, no random resizing!)\n",
    "    \"val\": torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Resize(256),\n",
    "            torchvision.transforms.CenterCrop(224),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "current_working_directory = Path.cwd()\n",
    "\n",
    "data_directory = load_hymenoptera_data()\n",
    "\n",
    "image_datasets = {\n",
    "    x: torchvision.datasets.ImageFolder(os.path.join(data_directory, x), data_transformations[x])\n",
    "    for x in [\"train\", \"val\"]\n",
    "}\n",
    "data_loaders = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=0)\n",
    "    for x in [\"train\", \"val\"]\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "\n",
    "display(\n",
    "    f\"Dataset dimensions: {dataset_sizes}\",\n",
    "    f\"Class names: {class_names}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2dd8de",
   "metadata": {
    "id": "4695db61"
   },
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(data_loaders[\"train\"]))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "plot_image(out, title=\", \".join([class_names[x] for x in classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184031b2",
   "metadata": {
    "id": "afbe1ee1"
   },
   "source": [
    "## Loading the pre-trained model\n",
    "\n",
    "...and replacing the final layer to repurpose the pre-trained model to detect bees and ants!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f4a57",
   "metadata": {
    "id": "727a526a"
   },
   "outputs": [],
   "source": [
    "# Fine-tuning the convolutional neural network\n",
    "# Load a pretrained model and reset final fully connected layer.\n",
    "model_to_finetune = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# We will create a new fully connected layer\n",
    "# The original model ended with a fully-connected layer called \"fc\", it's located at `.fc`\n",
    "# We'll use the same number inputs and give it only 2 outputs (for ants and bees)\n",
    "n_input_features = model_to_finetune.fc.in_features\n",
    "n_output_features = len(class_names)\n",
    "model_to_finetune.fc = nn.Linear(n_input_features, n_output_features)\n",
    "\n",
    "# Optimize the model for use with our device\n",
    "model_to_finetune = model_to_finetune.to(device)\n",
    "\n",
    "# Note that all parameters are being optimized\n",
    "optimizer_finetune = optim.SGD(model_to_finetune.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay learning rate by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_finetune, step_size=7, gamma=0.1)\n",
    "\n",
    "# Cross entropy loss will be the loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate the fine-tuned model\n",
    "model_to_finetune = train_model(\n",
    "    model_to_finetune, criterion, optimizer_finetune, exp_lr_scheduler, max_epochs=50, max_time=120\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a24e06",
   "metadata": {
    "id": "00140e24"
   },
   "source": [
    "## Now we'll show the model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912ca86",
   "metadata": {
    "id": "e0af4e4f"
   },
   "outputs": [],
   "source": [
    "visualize_model_predictions(model_to_finetune, batches=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f4075f",
   "metadata": {
    "id": "zYZXQYeVLGzp"
   },
   "source": [
    "# Pre-trained model as fixed feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967066a",
   "metadata": {
    "id": "40d9a5ae"
   },
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "model_with_ffe = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "# Freeze all the parameters\n",
    "for param in model_with_ffe.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Again, we will create a new fully connected layer\n",
    "# The code is identical but this time, this layer will be the only layer optimized\n",
    "n_input_features = model_with_ffe.fc.in_features\n",
    "n_output_features = len(class_names)\n",
    "model_with_ffe.fc = nn.Linear(n_input_features, n_output_features)\n",
    "model_with_ffe = model_with_ffe.to(device)\n",
    "\n",
    "# Optimize the model for use with our device\n",
    "model_with_ffe = model_with_ffe.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Only the final, fully-connected layer is being optimized.\n",
    "optimizer_ffe = optim.SGD(model_with_ffe.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay learning rate by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ffe, step_size=7, gamma=0.1)\n",
    "\n",
    "# Train and evaluate the fine-tuned model\n",
    "model_with_ffe = train_model(model_with_ffe, criterion, optimizer_ffe, exp_lr_scheduler, max_epochs=50, max_time=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90baa57b",
   "metadata": {
    "id": "cgPXBEG4LGzp"
   },
   "outputs": [],
   "source": [
    "visualize_model_predictions(model_with_ffe, batches=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c1c8f6",
   "metadata": {
    "id": "ZqdJU7m2MBhO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "id,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
