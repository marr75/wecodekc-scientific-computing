{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b5a55e",
   "metadata": {},
   "source": [
    "Section 1: Datasets\n",
    "\n",
    "Introduction\n",
    "\n",
    "Welcome to the first section of our lab! Today, we’ll learn about datasets in the Hugging Face ecosystem. Datasets\n",
    "are collections of data that we can use to train and evaluate machine learning models. Hugging Face provides an easy\n",
    "way to access and use a wide variety of datasets.\n",
    "\n",
    "Activities\n",
    "\n",
    " 1. Explore Dataset Pages on Hugging Face\n",
    "\t - We’ll start by looking at a few dataset pages on the Hugging Face website. This will help us understand what\n",
    "\t kind of datasets are available and how they are structured.\n",
    "   - [Rotten Tomato](https://huggingface.co/datasets/rotten_tomatoes)\n",
    "\t - [IMDb](https://huggingface.co/datasets/imdb)\n",
    "\t - [SQuAD](https://huggingface.co/datasets/squad)\n",
    "\t - [Tatoeba](https://huggingface.co/datasets/tatoeba)\n",
    "\t - [Wikipedia](https://huggingface.co/datasets/wikipedia\n",
    "   - [American Stories](https://huggingface.co/datasets/dell-research-harvard/AmericanStories)\n",
    "\t - [Food101](https://huggingface.co/datasets/food101)\n",
    "\t - [Wikiart](https://huggingface.co/datasets/huggan/wikiart)\n",
    "\t - [Wikiart Faces](https://huggingface.co/datasets/asahi417/wikiart-face)\n",
    "   - [People's Speech](https://huggingface.co/datasets/MLCommons/peoples_speech)\n",
    "\t - [A Complete Guide to Audio Datasets](https://huggingface.co/blog/audio-datasets)\n",
    " 2. Use the Dataset Viewer\n",
    "\t- Hugging Face has a dataset viewer that allows us to browse through the data without any coding. This is a\n",
    "\tgreat way to get a quick overview of the dataset.\n",
    "\t- Placeholder for URL to dataset viewer.\n",
    " 3. Load a Portion of a Dataset in Colab\n",
    "\t - We’ll hop into a Colab notebook to load a portion of a dataset. This will give us hands-on experience with\n",
    "\t using the Hugging Face datasets library.\n",
    "\t - We’ll look at some features like slicing, filtering, and shuffling the data.\n",
    "\n",
    "Key Points\n",
    "\n",
    "\t•\tHugging Face Datasets Library: A powerful tool for accessing and using various datasets.\n",
    "\t•\tDataset Pages: Provide information about each dataset, including descriptions and sample data.\n",
    "\t•\tDataset Viewer: An interactive tool to explore datasets.\n",
    "\t•\tColab Notebook: A practical environment to load and manipulate datasets.\n",
    "\n",
    "Let’s get started by exploring the Hugging Face dataset pages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1fdfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with text datasets\n",
    "# Load the Rotten Tomato dataset\n",
    "rotten_tomatoes = datasets.load_dataset(\"rotten_tomatoes\")\n",
    "# Display the dataset along with the first example\n",
    "display(rotten_tomatoes, rotten_tomatoes[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d8e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some datasets have \"idiosyncrasies\" that make them unique. For example, the American Stories dataset has a\n",
    "# \"subset_years\" argument that allows us to filter the dataset by year.\n",
    "# Load the American Stories dataset\n",
    "american_stories = datasets.load_dataset(\n",
    "    \"dell-research-harvard/AmericanStories\", \"subset_years\", year_list=[\"1809\", \"1810\"], trust_remote_code=True\n",
    ")\n",
    "# Display the dataset along with the first example\n",
    "display(american_stories, american_stories[\"1809\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f04e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with image datasets\n",
    "# Get a sample of 50 examples from the Food101 dataset\n",
    "food101_sample_50 = datasets.load_dataset(\"food101\", split=\"train[:50]\")\n",
    "# Get a sample of 1% of the examples from the Food101 dataset\n",
    "food101_sample_1_percent = datasets.load_dataset(\"food101\", split=\"train[:1%]\")\n",
    "# Display the samples, along with the last example in each sample set\n",
    "display(\n",
    "    food101_sample_50,\n",
    "    food101_sample_50[-1],\n",
    "    food101_sample_1_percent,\n",
    "    food101_sample_1_percent[-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619933cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with audio datasets\n",
    "# Audio datasets tend to be LARGE so your instructor will load the People's Speech dataset as a demonstration\n",
    "# Load the GigaSpeech dataset\n",
    "# import dotenv; dotenv.load_dotenv()\n",
    "# gigaspeech = datasets.load_dataset(\"speechcolab/gigaspeech\", \"dev\")\n",
    "# # Display the dataset along with the first example\n",
    "# display(gigaspeech, gigaspeech[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618780c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out for yourself\n",
    "# Load a dataset of your choice and display the first example(s)\n",
    "# Ask your instructor for suggestions or feel free to explore the Hugging Face website for inspiration!\n",
    "# If you have problems, copy paste the error into an AI assistant and see if it can help you and if not, ask your\n",
    "# instructor for help.\n",
    "# Replace \"______\" with the name of the dataset you want to load\n",
    "my_dataset = datasets.load_dataset(\"______\")\n",
    "# Display the dataset along with the first example\n",
    "# Replace the blanks with code to display the dataset and the first example\n",
    "_____(_____, _____[0])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
