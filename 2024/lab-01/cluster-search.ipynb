{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e0beb6",
   "metadata": {},
   "source": [
    "# Big Picture: Clustering and Search\n",
    "We can use word embeddings to perform clustering and search tasks.\n",
    "In this notebook, we will explore how to do this using a large word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers umap-learn plotly txtai -q --upgrade\n",
    "!wget -q https://raw.githubusercontent.com/marr75/wecodekc-scientific-computing/main/2024/lab-01/word_list.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f188de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from txtai import embeddings\n",
    "import word_list\n",
    "import sentence_transformers\n",
    "import umap\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b2b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_config = {\"path\": \"avsolatorio/GIST-small-Embedding-v0\", \"content\": True}\n",
    "\n",
    "# Create embeddings model\n",
    "embedding_engine = embeddings.Embeddings(embedding_config)\n",
    "ids = list(range(len(word_list.all_words)))\n",
    "embedding_engine.index(word_list.all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ce841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for items related to 'royal'\n",
    "embedding_engine.search(\"royal\", limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for items related to 'basketball'\n",
    "embedding_engine.search(\"basketball\", limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc63a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the word list\n",
    "encoder = sentence_transformers.SentenceTransformer(\"avsolatorio/GIST-small-Embedding-v0\")\n",
    "embedded_word_list = encoder.encode(word_list.all_words)\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "reduced_embedded_word_list = reducer.fit_transform(embedded_word_list)\n",
    "reduced_words_df = pd.DataFrame(reduced_embedded_word_list, columns=[\"x\", \"y\"])\n",
    "reduced_words_df[\"word\"] = word_list.all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1fe415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the reduced word embeddings\n",
    "fig = px.scatter(\n",
    "    reduced_words_df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    # text=\"word\",\n",
    "    hover_data=[\"word\"],\n",
    ")\n",
    "fig.update_layout(title=\"Word Embeddings Visualization\", xaxis_title=\"X\", yaxis_title=\"Y\", legend_title=\"Words\")\n",
    "fig.update_traces(marker_size=5)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
