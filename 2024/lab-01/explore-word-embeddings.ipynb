{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install sentence-transformers umap-learn plotly -q --upgrade"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import dataclasses\n",
    "\n",
    "import sentence_transformers\n",
    "import umap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Helpful tools\n",
    "# Define the encoder, which embeds words with it's encode method\n",
    "my_encoder = sentence_transformers.SentenceTransformer(\"avsolatorio/GIST-small-Embedding-v0\")\n",
    "# Define the reducer, which reduces the dimensionality of the embeddings\n",
    "my_reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class EmbeddedWord:\n",
    "    \"\"\"\n",
    "    A dataclass to store the word, its embedding, and its reduced embedding\n",
    "    \"\"\"\n",
    "\n",
    "    word: str\n",
    "    embedding: np.ndarray\n",
    "    reduced_embedding: np.ndarray\n",
    "    notes: str = \"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def from_words(words, encoder=my_encoder, reducer=my_reducer, fit=True):\n",
    "        \"\"\"\n",
    "        Encode a list of words using the encoder and reduce their dimensionality then return a list of EmbeddedWord\n",
    "        \"\"\"\n",
    "        embeddings = encoder.encode(words)\n",
    "        if fit:\n",
    "            embeddings_reduced = reducer.fit_transform(embeddings)\n",
    "        else:\n",
    "            embeddings_reduced = reducer.transform(embeddings)\n",
    "        return [\n",
    "            EmbeddedWord(word, embedding, reduced_embedding)\n",
    "            for word, embedding, reduced_embedding in zip(words, embeddings, embeddings_reduced)\n",
    "        ]\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"\n",
    "        Add two EmbeddedWord objects\n",
    "        \"\"\"\n",
    "        return EmbeddedWord(\n",
    "            f\"{self.word} + {other.word}\",\n",
    "            self.embedding + other.embedding,\n",
    "            self.reduced_embedding + other.reduced_embedding,\n",
    "        )\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        \"\"\"\n",
    "        Subtract two EmbeddedWord objects\n",
    "        \"\"\"\n",
    "        return EmbeddedWord(\n",
    "            f\"{self.word} - {other.word}\",\n",
    "            self.embedding - other.embedding,\n",
    "            self.reduced_embedding - other.reduced_embedding,\n",
    "        )\n",
    "\n",
    "\n",
    "def make_dataframe_from_words(embedded_words):\n",
    "    \"\"\"\n",
    "    Create a DataFrame from a list of words\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"words\": embedded_word.word,\n",
    "                \"x\": embedded_word.reduced_embedding[0],\n",
    "                \"y\": embedded_word.reduced_embedding[1],\n",
    "            }\n",
    "            for embedded_word in embedded_words\n",
    "        ]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_words(words_df):\n",
    "    \"\"\"\n",
    "    Plot the words DataFrame\n",
    "    \"\"\"\n",
    "    fig = px.scatter(words_df, x=\"x\", y=\"y\", text=\"words\", size_max=60, template=\"plotly_white\")\n",
    "    fig.update_layout(\n",
    "        title=\"Word Embeddings Visualization\",\n",
    "        xaxis_title=\"Component 1\",\n",
    "        yaxis_title=\"Component 2\",\n",
    "        legend_title=\"Words\",\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def append_embedded_word_into_df(words_df, embedded_word):\n",
    "    \"\"\"\n",
    "    Add two words and their computed embedding into the DataFrame\n",
    "    \"\"\"\n",
    "    words_df.loc[len(words_df.index)] = [embedded_word.word, *embedded_word.reduced_embedding]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "words = [\"king\", \"queen\", \"man\", \"woman\", \"monarch\"]\n",
    "embedded_words = EmbeddedWord.from_words(words)\n",
    "embedded_king, embedded_queen, embedded_man, embedded_woman, embedded_monarch = embedded_words\n",
    "words_df = make_dataframe_from_words(embedded_words)\n",
    "computed_queen = embedded_king - embedded_man + embedded_woman\n",
    "append_embedded_word_into_df(words_df, computed_queen)\n",
    "\n",
    "plot_words(words_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Explore on your own\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
